{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Perception Analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the necessary imports\n",
    "import argparse\n",
    "import shutil\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socketio\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "from PIL import Image\n",
    "from flask import Flask\n",
    "from io import BytesIO, StringIO\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "# Import functions for perception and decision making\n",
    "from perception import perception_step\n",
    "from decision import decision_step\n",
    "from supporting_functions import update_rover, create_output_images\n",
    "# Initialize socketio server and Flask application \n",
    "# (learn more at: https://python-socketio.readthedocs.io/en/latest/)\n",
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Read in ground truth map and create 3-channel green version for overplotting\n",
    "# NOTE: images are read in by default with the origin (0, 0) in the upper left\n",
    "# and y-axis increasing downward.\n",
    "ground_truth = mpimg.imread('../calibration_images/map_bw.png')\n",
    "# This next line creates arrays of zeros in the red and blue channels\n",
    "# and puts the map into the green channel.  This is why the underlying \n",
    "# map output looks green in the display image\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "# Define RoverState() class to retain rover state parameters\n",
    "class RoverState():\n",
    "    def __init__(self):\n",
    "        self.start_time = None # To record the start time of navigation\n",
    "        self.total_time = None # To record total duration of naviagation\n",
    "        self.img = None # Current camera image\n",
    "        self.pos = None # Current position (x, y)\n",
    "        self.yaw = None # Current yaw angle\n",
    "        self.pitch = None # Current pitch angle\n",
    "        self.roll = None # Current roll angle\n",
    "        self.vel = None # Current velocity\n",
    "        self.steer = 0 # Current steering angle\n",
    "        self.throttle = 0 # Current throttle value\n",
    "        self.brake = 0 # Current brake value\n",
    "        self.nav_angles = None # Angles of navigable terrain pixels\n",
    "        self.nav_dists = None # Distances of navigable terrain pixels\n",
    "        self.ground_truth = ground_truth_3d # Ground truth worldmap\n",
    "        self.mode = 'forward' # Current mode (can be forward or stop)\n",
    "        self.throttle_set = 0.2 # Throttle setting when accelerating\n",
    "        self.brake_set = 10 # Brake setting when braking\n",
    "        # The stop_forward and go_forward fields below represent total count\n",
    "        # of navigable terrain pixels.  This is a very crude form of knowing\n",
    "        # when you can keep going and when you should stop.  Feel free to\n",
    "        # get creative in adding new fields or modifying these!\n",
    "        self.stop_forward = 50 # Threshold to initiate stopping\n",
    "        self.go_forward = 500 # Threshold to go forward again\n",
    "        self.max_vel = 2 # Maximum velocity (meters/second)\n",
    "        # Image output from perception step\n",
    "        # Update this image to display your intermediate analysis steps\n",
    "        # on screen in autonomous mode\n",
    "        self.vision_image = np.zeros((160, 320, 3), dtype=np.float) \n",
    "        # Worldmap\n",
    "        # Update this image with the positions of navigable terrain\n",
    "        # obstacles and rock samples\n",
    "        self.worldmap = np.zeros((200, 200, 3), dtype=np.float) \n",
    "        self.samples_pos = None # To store the actual sample positions\n",
    "        self.samples_found = 0 # To count the number of samples found\n",
    "        self.near_sample = 0 # Will be set to telemetry value data[\"near_sample\"]\n",
    "        self.picking_up = 0 # Will be set to telemetry value data[\"picking_up\"]\n",
    "        self.send_pickup = False # Set to True to trigger rock pickup\n",
    "# Initialize our rover \n",
    "Rover = RoverState()\n",
    "\n",
    "# Variables to track frames per second (FPS)\n",
    "# Intitialize frame counter\n",
    "frame_counter = 0\n",
    "# Initalize second counter\n",
    "second_counter = time.time()\n",
    "fps = None\n",
    "\n",
    "\n",
    "# Define telemetry function for what to do with incoming data\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "\n",
    "    global frame_counter, second_counter, fps\n",
    "    frame_counter+=1\n",
    "    # Do a rough calculation of frames per second (FPS)\n",
    "    if (time.time() - second_counter) > 1:\n",
    "        fps = frame_counter\n",
    "        frame_counter = 0\n",
    "        second_counter = time.time()\n",
    "    print(\"Current FPS: {}\".format(fps))\n",
    "\n",
    "    if data:\n",
    "        global Rover\n",
    "        # Initialize / update Rover with current telemetry\n",
    "        Rover, image = update_rover(Rover, data)\n",
    "\n",
    "        if np.isfinite(Rover.vel):\n",
    "\n",
    "            # Execute the perception and decision steps to update the Rover's state\n",
    "            Rover = perception_step(Rover)\n",
    "            Rover = decision_step(Rover)\n",
    "\n",
    "            # Create output images to send to server\n",
    "            out_image_string1, out_image_string2 = create_output_images(Rover)\n",
    "\n",
    "            # The action step!  Send commands to the rover!\n",
    "            commands = (Rover.throttle, Rover.brake, Rover.steer)\n",
    "            send_control(commands, out_image_string1, out_image_string2)\n",
    " \n",
    "            # If in a state where want to pickup a rock send pickup command\n",
    "            if Rover.send_pickup and not Rover.picking_up:\n",
    "                send_pickup()\n",
    "                # Reset Rover flags\n",
    "                Rover.send_pickup = False\n",
    "        # In case of invalid telemetry, send null commands\n",
    "        else:\n",
    "\n",
    "            # Send zeros for throttle, brake and steer and empty images\n",
    "            send_control((0, 0, 0), '', '')\n",
    "\n",
    "        # If you want to save camera images from autonomous driving specify a path\n",
    "        # Example: $ python drive_rover.py image_folder_path\n",
    "        # Conditional to save image frame if folder was specified\n",
    "        if args.image_folder != '':\n",
    "            timestamp = datetime.utcnow().strftime('%Y_%m_%d_%H_%M_%S_%f')[:-3]\n",
    "            image_filename = os.path.join(args.image_folder, timestamp)\n",
    "            image.save('{}.jpg'.format(image_filename))\n",
    "\n",
    "    else:\n",
    "        sio.emit('manual', data={}, skip_sid=True)\n",
    "\n",
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control((0, 0, 0), '', '')\n",
    "    sample_data = {}\n",
    "    sio.emit(\n",
    "        \"get_samples\",\n",
    "        sample_data,\n",
    "        skip_sid=True)\n",
    "\n",
    "def send_control(commands, image_string1, image_string2):\n",
    "    # Define commands to be sent to the rover\n",
    "    data={\n",
    "        'throttle': commands[0].__str__(),\n",
    "        'brake': commands[1].__str__(),\n",
    "        'steering_angle': commands[2].__str__(),\n",
    "        'inset_image1': image_string1,\n",
    "        'inset_image2': image_string2,\n",
    "        }\n",
    "    # Send commands via socketIO server\n",
    "    sio.emit(\n",
    "        \"data\",\n",
    "        data,\n",
    "        skip_sid=True)\n",
    "    eventlet.sleep(0)\n",
    "# Define a function to send the \"pickup\" command \n",
    "def send_pickup():\n",
    "    print(\"Picking up\")\n",
    "    pickup = {}\n",
    "    sio.emit(\n",
    "        \"pickup\",\n",
    "        pickup,\n",
    "        skip_sid=True)\n",
    "    eventlet.sleep(0)\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument(\n",
    "        'image_folder',\n",
    "        type=str,\n",
    "        nargs='?',\n",
    "        default='',\n",
    "        help='Path to image folder. This is where the images from the run will be saved.'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    os.system('rm -rf IMG_stream/*')\n",
    "    if args.image_folder != '':\n",
    "        print(\"Creating image folder at {}\".format(args.image_folder))\n",
    "        if not os.path.exists(args.image_folder):\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        print(\"Recording this run ...\")\n",
    "    else:\n",
    "        print(\"NOT recording this run ...\")\n",
    "    \n",
    "    # wrap Flask application with socketio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
